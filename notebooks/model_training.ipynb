{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "data = pd.read_csv(\"../data/data_without_na.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating features and labels\n",
    "X = data.drop(\"outcome\", axis=1)\n",
    "y = data.outcome\n",
    "\n",
    "# feature selection\n",
    "X.drop([\"skin_thickness\"], axis=1, inplace=True)\n",
    "\n",
    "# splitting into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "\n",
    "# normalizing X_train\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "# flattening y_train\n",
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "logistic_regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "# probabilities on training data\n",
    "probs = logistic_regression.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation probabilities\n",
    "cross_val_proba = cross_val_predict(logistic_regression, X_train, y_train, method=\"predict_proba\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for given threshold\n",
    "def custom_predict(probabilities, threshold): \n",
    "    return (probabilities[:, 1] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7925311203319502\n",
      "0.60062893081761\n"
     ]
    }
   ],
   "source": [
    "# scores on training data\n",
    "thresh_predictions = custom_predict(probs, threshold=0.3)\n",
    "print(recall_score(y_train, thresh_predictions))\n",
    "print(precision_score(y_train, thresh_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7842323651452282\n",
      "0.6019108280254777\n"
     ]
    }
   ],
   "source": [
    "# scores on cross validation\n",
    "thresh_predictions = custom_predict(cross_val_proba, threshold=0.3)\n",
    "print(recall_score(y_train, thresh_predictions))\n",
    "print(precision_score(y_train, thresh_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_classifier = SVC(kernel=\"linear\", probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "support_vector_classifier.fit(X_train, y_train)\n",
    "# probabilities on training data\n",
    "probs = support_vector_classifier.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation probabilities\n",
    "cross_val_proba = cross_val_predict(support_vector_classifier, X_train, y_train, method=\"predict_proba\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8049792531120332\n",
      "0.610062893081761\n"
     ]
    }
   ],
   "source": [
    "# scores on training data\n",
    "thresh_predictions = custom_predict(probs, threshold=0.3)\n",
    "print(recall_score(y_train, thresh_predictions))\n",
    "print(precision_score(y_train, thresh_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7925311203319502\n",
      "0.6044303797468354\n"
     ]
    }
   ],
   "source": [
    "# scores on cross validation\n",
    "thresh_predictions = custom_predict(cross_val_proba, threshold=0.3)\n",
    "print(recall_score(y_train, thresh_predictions))\n",
    "print(precision_score(y_train, thresh_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming test data\n",
    "X_test = scalar.transform(X_test)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "probs = support_vector_classifier.predict_proba(X_test)\n",
    "predictions = custom_predict(probs, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8518518518518519\n",
      "0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "# recall and precision score\n",
    "print(recall_score(y_test, predictions))\n",
    "print(precision_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/support_vector_classifier.pkl']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model as 'support_vector_classifier.pkl'\n",
    "joblib.dump(support_vector_classifier, \"../models/support_vector_classifier.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e9e12bc012fae32ac9654bb37cb31a0d4c91164effa766e52fa90ec4ccf2e77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
